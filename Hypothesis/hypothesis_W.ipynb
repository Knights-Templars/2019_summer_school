{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing Workshop\n",
    "\n",
    "In the following exercises we will use the data of the teaching session, the **absolute magnitudes** (*2MASS* $K_s$-band) of **Galactic** globular clusters.\n",
    "\n",
    "We will also load a new dataset containing the **apparent magnitudes** (in the same band) of globular clusters in the ** *Andromeda Galaxy* (M31)**.\n",
    "\n",
    "Let's load the packages and data that are necessary for the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "absolute_MWG = np.loadtxt(\"data/GC_MWG_absolute.dat\")\n",
    "apparent_M31 = np.loadtxt(\"data/GC_M31_apparent.dat\")\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.title(\"Milky Way\")\n",
    "plt.hist(absolute_MWG, bins=20)\n",
    "plt.xlabel(\"K-band absolute magnitude\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"M31\")\n",
    "plt.hist(apparent_M31, bins=20)\n",
    "plt.xlabel(\"K-band apparent magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: distribution of M31 globular clusters\n",
    "\n",
    "## (a) Is the M31 data normally distributed? \n",
    "\n",
    "Use **at least two different parametric tests** from `scipy.stats` https://docs.scipy.org/doc/scipy/reference/stats.html.\n",
    "You can try the `shapiro` or `normaltest` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st test\n",
    "_, pvalue = st.\n",
    "print(\"p-value: {:.3g}\".format(pvalue))\n",
    "\n",
    "alpha =\n",
    "if pvalue < alpha:\n",
    "    print(\"It is not normally distributed.\")\n",
    "else:\n",
    "    print(\"It is normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd test\n",
    "_, pvalue = st.\n",
    "print(\"p-value: {:.3g}\".format(pvalue))\n",
    "\n",
    "alpha =\n",
    "if pvalue < alpha:\n",
    "    print(\"It is not normally distributed.\")\n",
    "else:\n",
    "    print(\"It is normally distributed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Test the normality of the M31 data using the Kolmogorov-Smirnov test.\n",
    "\n",
    "* Use the K-S test to test for normality. What is your choice for the location and scale of the Gaussian distribution you test the data against?\n",
    "\n",
    "* What is the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = st.norm(loc=, scale=)\n",
    "\n",
    "_, pvalue = st.kstest(apparent_M31, dist.cdf)\n",
    "print(\"p-value: {:.3g}\".format(pvalue))\n",
    "\n",
    "alpha =\n",
    "if pvalue < alpha:\n",
    "    print(\"It is not normally distributed.\")\n",
    "else:\n",
    "    print(\"It is normally distributed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) EXTRA CREDIT: shortcoming of the K-S test\n",
    "\n",
    "* Why is the $p$-value large in the case of Kolmogorov-Smirnov test? What is the weakness of the K-S test?\n",
    "\n",
    "* In the following code block, we plot the empirical/theoretical PDFs and CDFs. Any clues from that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the empirical PDF and the normal approximation superposed...\n",
    "x_values = np.linspace(min(apparent_M31), max(apparent_M31), 200)\n",
    "plt.figure()\n",
    "plt.hist(apparent_M31, bins=20, density=True)\n",
    "plt.plot(x_values, dist.pdf(x_values))\n",
    "plt.show()\n",
    "\n",
    "# Why does the K-S test gives such a high p-value? Let's look at the CDF.\n",
    "plt.figure()\n",
    "x_empirical = np.sort(apparent_M31)\n",
    "y_empirical = np.linspace(0.0, 1.0, len(x_empirical))\n",
    "\n",
    "plt.step(x_empirical, y_empirical, \"k-\")\n",
    "plt.plot(x_empirical, dist.cdf(x_empirical), \"r--\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can rely on Shapiro-Wilk for testing normality but what if we had another distribution, is there another choice?\n",
    "\n",
    "Let's see the result of the *Anderson-Darling test*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-D test implementation in `scipy.stats` provides the critical values for\n",
    "statistic, critical_values, significance_levels = st.anderson(apparent_M31, dist=\"norm\")\n",
    "print(\"Statistic: {:.4g}\".format(statistic))\n",
    "for critical_value, significance_level in zip(critical_values, significance_levels):\n",
    "    outcome = \"OK\" if statistic < critical_value else \"FAIL\"\n",
    "    print(\"At {:4.1f} level, the critical value is {:4.2g}: {}\".format(significance_level, critical_value, outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) What are the variances of M31 and Milky Way data? Are the significantly different? \n",
    "\n",
    "In https://docs.scipy.org/doc/scipy/reference/stats.html you can find various `scipy.stats` functions for testing equal variances. **Use at least two of the available methods**. You can try Levene, Bartlett, or Filgner-Killen tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =\n",
    "\n",
    "print(\"MWG variance = {:.4f}\".format(np.var(absolute_MWG)))\n",
    "print(\"M31 variance = {:.4f}\".format(np.var(apparent_M31)))\n",
    "\n",
    "print()\n",
    "print(\"Test                     p-value | Decision\")\n",
    "print(\"-------------------------------------------\")\n",
    "_, pvalue = st.\n",
    "print(\"Levene test              {:.2g} | {} equal\".format(pvalue, \"\" if pvalue > alpha else \"not\"))\n",
    "\n",
    "_, pvalue = st.\n",
    "print(\"Bertlett's test          {:.2g} | {} equal\".format(pvalue, \"\" if pvalue > alpha else \"not\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: the distance of M31\n",
    "\n",
    "In this exercise we will compute the distance of M31 by using the data from Exercise 1.\n",
    "\n",
    "## (a) Compute the distance of M31\n",
    "\n",
    "* Assumption 1: the globular clusters in Milky Way look like the ones in M31!\n",
    "\n",
    "    This means that the luminosity distribution of the GLs in both galaxies is the same. In addition to that, we assume that the spectral properties are also similar: for the same luminosity we would get the same absolute magnitude in the $K_s$ band.\n",
    "\n",
    "    Therefore, we would expect that the mean absolute magnitude of both populations is the same.\n",
    "    \n",
    "\n",
    "* Assumption 2: our survey is complete!\n",
    "\n",
    "    There are multiple obstacles in getting the full population of globular clusters: in the Milky Way we might miss those that are behind the MW disk and those not covered by surveys (our galaxy covers the whole sky!) In extragalactic surveys, due to the sensitivity limit, we might be able to observe only the brightest GCs.\n",
    "\n",
    "    For the purpose of this exercise we assume that we got the full population, although there are statistical methods to **correct for incompleteness**.\n",
    "    \n",
    "\n",
    "* Remember that the distance modulus $\\mu$, the absolute $M$ and apparent magnitude $m$ are connected through the formula:\n",
    "\n",
    "    $$ \\mu = m - M $$\n",
    "    \n",
    "    Also, the metric distance $d$ (in Mpc) can be computed from the distance modulus using\n",
    "\n",
    "    $$ d = 10^{\\frac{\\mu}{5} - 5} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and its uncertainty for the Milky Way galaxy (MWG) and M31 galaxy...\n",
    "mwg_mean, mwg_sem = ..., ...\n",
    "m31_mean, m31_sem = ..., ...\n",
    "print(\"Milky way mean absolute magnitude: {:.2f} +/- {:.2f}\".format(mwg_mean, mwg_sem))\n",
    "print(\"Andromeda mean apparent magnitude: {:.2f} +/- {:.2f}\".format(m31_mean, m31_sem))\n",
    "\n",
    "def modulus_to_Mpc(distance_modulus):\n",
    "    \"\"\"Convert a distance modulus to metric distance in Mpc.\"\"\"\n",
    "    return 10.0 ** (distance_modulus / 5.0 - 5)\n",
    "\n",
    "modulus = \n",
    "distance = \n",
    "print(\"Distance modulus = {:.3f}\".format(modulus))\n",
    "print(\"Distance = {:.3g} Mpc\".format(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Use error propagation to estimate the uncertainty on the distance modulus\n",
    "\n",
    "If $A$ and $B$ are random variables with standard deviations $\\sigma_A$ and $\\sigma_B$ respectively, then their **difference**\n",
    "\n",
    "$$C = A - B$$\n",
    "\n",
    "will have standard deviation\n",
    "\n",
    "$$\\sigma_C = \\sqrt{\\sigma_A^2 + \\sigma_B^2}$$\n",
    "\n",
    "#### EXTRA CREDIT: report the uncertainty on the metric distance? \n",
    "\n",
    "Remember that the uncertainties on the distance moduli are Gaussian and therefore symmetric...is it so for the metric distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the 'quadratic sum'\n",
    "modulus_error = \n",
    "print(\"Distance moudlus = {:.3f} +/- {:.3f}\".format(modulus, modulus_error))\n",
    "\n",
    "# extra credit: report metric distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Is the computed distance modulus consistent with the Cepheid estimate: $24.44 \\pm 0.10\\ \\rm mag$?\n",
    "\n",
    "The value is taken from\n",
    "> Madore et al. 1991, PASP, 103, 933M\n",
    "\n",
    "**HINT 1**: assuming that the uncertainties on both our estimate and the Cepheid one are Gaussian, what is distribution of their difference?\n",
    "\n",
    "**HINT 2**: what *consistent* means in terms of the difference? What test can we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cep_modulus = 24.44\n",
    "cep_modulus_error = 0.1\n",
    "\n",
    "print(\"Cepheid distance modulus = {:.2f} +/- {:.2f}\".format(cep_modulus, cep_modulus_error))\n",
    "cep_distance = modulus_to_Mpc(cep_modulus)\n",
    "cep_lower68 = modulus_to_Mpc(cep_modulus - cep_modulus_error)\n",
    "cep_upper68 = modulus_to_Mpc(cep_modulus + cep_modulus_error)\n",
    "print(\"Cepheid distance = {:.3f} Mpc    |     68% CI: ({:.3f}, {:.3f}) Mpc\".\n",
    "      format(cep_distance, cep_lower68, cep_upper68))\n",
    "\n",
    "# plot the two estimates' probability density\n",
    "x = np.linspace(24, 25.5, 100)\n",
    "y_result = st.norm.pdf(x, loc=modulus, scale=modulus_error)\n",
    "y_theory = st.norm.pdf(x, loc=cep_modulus, scale=cep_modulus_error)\n",
    "plt.figure()\n",
    "plt.plot(x, y_result, label=\"Our result\")\n",
    "plt.plot(x, y_theory, label=\"Literature\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Distance modulus (mag)\")\n",
    "plt.ylabel(\"Probability density\")\n",
    "plt.show()\n",
    "\n",
    "# HYPOTHESIS TESTING\n",
    "\n",
    "# we may consider that the two estimates are consistent by testing whether their difference is consistent with zero\n",
    "\n",
    "# we decide a significance level 5%\n",
    "a =\n",
    "\n",
    "# take the difference and its error (using propagation theory)\n",
    "difference = \n",
    "difference_error =\n",
    "\n",
    "# assuming normal distribution for the sample mean and the Cepheid estimate...\n",
    "# their difference will also be normally distributed and we can use the Z-score to get a p-value\n",
    "p_value = \n",
    "print(\"p-value = {:.3f}\".format(p_value))\n",
    "if p_value < a:\n",
    "    print(\"The two estimates are not consistent.\")\n",
    "else:\n",
    "    print(\"The two estimates are consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) From the distance estimate, calculate the absolute magnitudes of M31 GCs. Check if they follow the same distribution as the absolute magnitude of Milky Way GCs.\n",
    "\n",
    "Use two methods. The 2-sample K-S statistic (`scipy.stats.ks_2samp`) and Wilcoxon rank-sum (`scipy.stats.ranksums`) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_M31 =\n",
    "\n",
    "# Looking at the distributions\n",
    "x_min = min(min(absolute_M31), min(absolute_MWG))\n",
    "x_max = max(max(absolute_M31), max(absolute_MWG))\n",
    "bins = np.linspace(x_min, x_max, 20)\n",
    "plt.hist(absolute_M31, bins=bins, density=True, histtype=\"step\")\n",
    "plt.hist(absolute_MWG, bins=bins, density=True, histtype=\"step\")\n",
    "plt.show()\n",
    "\n",
    "print(\"K-S 2-sample test\")\n",
    "statistic, pvalue = st.\n",
    "print(\"  Statistic:  {:.3g}\".format(statistic))\n",
    "print(\"  p-value  :  {:.3g}\".format(pvalue))\n",
    "\n",
    "print(\"Wilcoxon rank-sum\")\n",
    "statistic, pvalue = st.\n",
    "print(\"  Statistic:  {:.3g}\".format(statistic))\n",
    "print(\"  p-value  :  {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit: normal approximation of Poisson distributions\n",
    "\n",
    "It is known that the normal distribution is a good approximation of Poisson distribution when the parameter $\\lambda$ is large.\n",
    "\n",
    "1. Can you quantify this claim using sampling and hypothesis testing? Choose a sample size $N$ and some $\\lambda$ values.\n",
    "\n",
    "2. Do the results depend on the sample size?\n",
    "\n",
    "3. Do the results depend on the testing method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sample_size = \n",
    "poisson_means_to_test = [0.5, ..., 10, ...]\n",
    "for poisson_mean in poisson_means_to_test:\n",
    "    sample = st.poisson.rvs(poisson_mean, size=sample_size)\n",
    "    \n",
    "    # shapiro test\n",
    "    statistic, pvalue = st.\n",
    "    print(\"For l={:.3g}\".format(poisson_mean))\n",
    "    print(\"  SW: p-value = {:.3g}\".format(pvalue))\n",
    "    \n",
    "    # k-s test\n",
    "    norm_cdf = st.norm(loc=..., scale=...).cdf\n",
    "    statistic, pvalue = st.kstest(sample, norm_cdf)\n",
    "    print(\"  KS: p-value = {:.3g}\".format(pvalue))\n",
    "    \n",
    "    nbins = min(15, max(sample) - min(sample) + 1)\n",
    "    plt.hist(sample, bins=nbins, label=r\"$\\lambda = {:.2g}$\".format(poisson_mean), histtype=\"step\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
